---
title: "Final_data_clean"
author: "Group2"
date: "2024-08-21"
output:
  html_document:
    code_folding: hide
    toc: true
    toc_depth: 3
    toc_float:
      collapsed: true
      smooth_scroll: true
table-of-contents: true 
number-sections: true 
embed-resources: true 
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
library(tidyverse)
library(here)      
library(readxl)    
library(janitor)   
library(stringr)   
library(tidyr)     
library(dplyr)
library(knitr)
library(ggplot2)
library(factoextra)
library(gt)
library(naniar)
library(ggcorrplot)
library(corrplot)
library(GGally)
library(randomForest)
library(pdp)
library(e1071)  
library(dplyr) 
library(caret)
```


# Data cleaning & EDA & Pre-processing

## Section 1: Load in the datasets
We first load in the useful data sets we need including the original population and indigenous population. Here we first merged two datasets (bb/bp) for original populations using primary key (ABSPID). We also merged three data sets (bsp/bhh/bcn) for indigenous population by (ABSGID & ABSHID). We renamed the column names to keep consistency.

At the same time, we then add a column which indicate whether the person is in the original population or indigenous populaiotn (binary result).
```{r}
raw_bp <- read.csv(here("ZIPallFiles","AHSnpa11bp.csv"), header=TRUE)
raw_bb <- read.csv(here("ZIPallFiles","AHSnpa11bb.csv"), header=TRUE)
bp_bb <- inner_join(raw_bp, raw_bb, by = "ABSPID") %>%
  rename(SOCIAL = SF2SA1QN) %>%
   mutate(Identity = factor(0))

raw_bsp <- read.csv(here("ZIPallFiles","inp13bsp.csv"), header=TRUE)
raw_bcn <- read.csv(here("ZIPallFiles","inp13bcn.csv"), header=TRUE)
raw_bhh <- read.csv(here("ZIPallFiles","inp13bhh.csv"), header=TRUE)



bsp_bcn_bhh<- left_join(raw_bsp, raw_bhh,by = c("ABSHID")) %>%
  filter(!ABSHID %in% raw_bcn$ABSHID[raw_bcn$ICD10ME %in% c(7, 20)])%>%
  rename(AGEC =AGEEC, SOCIAL = SF2SA1DB)%>%
   mutate(Identity = factor(1))
```
When loading the indigenous population data set, we also filter out the people who have hypertension and taking medication.

## Section 2: Select and merge
We start to clean the data and first as we only looking at the population who are not currently have medication relating to blood pressure, also we focus on the adults and population who are not currently pregnant, so we only focus on the target population in our analysis.

```{r}
bp_bb <- bp_bb %>%
  filter(
    AGEC >= 18, 
    HYPBC == 5,
    SABDYMS != 4
    )
bsp_bcn_bhh <- bsp_bcn_bhh %>% 
  filter(
    AGEC >= 18, 
    SABDYMS != 4)
```


Next, we merged two populations into the one whole population and name this big data set as raw_data.

```{r}
raw_data <- bind_rows(bp_bb,bsp_bcn_bhh)
```

The useful variables then been selected including all predictors, response variables, and confounding variables.

```{r}
selected_data <- raw_data %>%
select(
    ABSPID, ABSHID, SOCIAL, AGEC, SEX, BMISC, SYSTOL, DIASTOL,
    SMKSTAT, ALCPER1, ALCPER2,
    POTAST1, POTAST2, 
    SODIUMT1, SODIUMT2,
    FIBRPER1, FIBRPER2, 
    CHOPER1, CHOPER2,
    Identity
  )


```

## Section 3: Missing values encoding & data types conversion & Imbalance class

### 3.1 Missing values encoding and data types conversion
In next step we encode all missing values base on the data dictionary and correct all data types. At the same time we calculate the average of those two-days variables.

```{r}

variable_info <- data.frame(
  Variable = names(selected_data),
  Type = sapply(selected_data, class)
)

variable_info %>%
  gt() %>%
  tab_header(
    title = "Variable Names and Their Types"
  ) %>%
 tab_caption(caption = md("Table 1: Variable types table"))
```


```{r}
selected_data <- selected_data %>%
  mutate(
    across(c(SEX, SOCIAL, SMKSTAT), ~ as.factor(.)),
    BMISC = na_if(na_if(BMISC, 99), 98),
    SYSTOL = na_if(na_if(na_if(SYSTOL,0),998),999),
    DIASTOL = na_if(na_if(na_if(DIASTOL,0),998),999),
    POTAST = (POTAST1 + POTAST2) / 2, 
    SODIUMT = (SODIUMT1 + SODIUMT2) / 2,
    FIBRPER = (FIBRPER1 + FIBRPER2)/2,
    CHOPER = (CHOPER1 + CHOPER2) / 2,
    ALCPER = (ALCPER1 + ALCPER2) /2
    ) %>%
 select(
    ABSPID,ABSHID, SOCIAL, AGEC, SEX, BMISC, SYSTOL, DIASTOL,
    SMKSTAT, ALCPER,
    POTAST, 
    SODIUMT,
    FIBRPER, 
    CHOPER,
    Identity
  )
```

We had a look at the types after we changed.

```{r}

variable_info <- data.frame(
  Variable = names(selected_data),
  Type = sapply(selected_data, class)
)

variable_info %>%
  gt() %>%
  tab_header(
    title = "Variable Names and Their Types"
  ) %>%
 tab_caption(caption = md("Table 2: Variable types table after correction"))
```

### 3.2 Factor variables class distribution
```{r}

plot_categorical_distribution <- function(data) {
  categorical_vars <- data %>%
    select(where(is.factor) | where(is.character)) %>%
    select(-ABSPID, -ABSHID)
  
  for (var in names(categorical_vars)) {
    non_na_data <- data %>%
      filter(!is.na(.data[[var]]))
    
    if (nrow(non_na_data) == 0) next
    
    p <- ggplot(non_na_data, aes(x = .data[[var]])) +
      geom_bar(aes(y = (..count..) / sum(..count..), fill = .data[[var]]), color = "black") +
      scale_fill_brewer(palette = "Set3") + 
      labs(title = paste("Proportion of Categories in", var), 
           x = "Category", 
           y = "Proportion") +
      theme_minimal() +
      theme(axis.text.x = element_text(angle = 45, hjust = 1))  
    
    print(p)
  }
}

plot_categorical_distribution(selected_data)       
```

Base on the dictionary there are no big difference between category 1, 2, and 3, as they are all people who currently smoke.

```{r}
#selected_data <- selected_data %>% 
 # mutate(SMKSTAT = recode(SMKSTAT, "2" = "1", "3" = "1","4" = "2","5" = "3"))

```

```{r}
plot_categorical_distribution(selected_data) 
```


## Section 4: Duplicate rows identification

Then the duplicate values been checked, we found no duplicate values.
```{r}

unique_data <- selected_data %>%
  select(-ABSPID) %>%
  distinct()

dims <- dim(unique_data)

dims_table <- tibble::tibble(
  Dimension = c("Rows", "Columns"),
  Count = dims
)
dims_table %>%
  gt() %>%
  tab_header(
    title = "Dimensions of Unique Tibble"
  )%>%
 tab_caption(caption = md("Table 3: Dimensions table"))
```



## Section 5: Missing values cleaning

### 5.1 Missing values identification
The summary statistic of missing values been shown below, we found there occurs some missingness in BMI and blood pressure measurments.

```{r warning = FALSE}
data2 <- selected_data %>%
  select(-ABSPID,-ABSHID)
miss_summary <- miss_var_summary(data2)
kable(miss_summary, digits = 2, format = "html")
```

Then looking in to the missingness pattern,this missingness plot provides an overview of missing values for each variable in our data set, the majority of variables have 0% missing values, with only three variables showing missing data (BMISC, SYSTOL, and DIASTOL) at around 13-14%.
The missing values seem to follow a consistent pattern across the observations (rows) for the BMISC, SYSTOL, and DIASTOL variables. 

```{r}
vis_miss(data2)
```

### 5.2 Regression imputation for missing values

Base on the patterns we found, we decide to use regression imputation to deal with those small proportion of missingness,

```{r}
data <- selected_data 
corr_matrix <- data%>%
  select(where(is.numeric)) %>%
  mutate(across(everything(), ~ ifelse(is.na(.), mean(., na.rm = TRUE), .))) %>%
  cor(use = "complete.obs")

ggcorrplot(corr_matrix, lab = TRUE, 
           title = "Correlation Heatmap for ALL", 
           colors = c("blue", "white", "red"),
           tl.cex = 9, lab_size = 4) + theme(legend.position = "none")

```
AS observed from the heat map, we can tell that the two most significant (except blood pressure) multicollinearity is between energy percentage from carbohydrate and fibers, also between the sodium and potassium. So we decide to only choose one between each to do the regression imputation for missing values.


```{r}
# 1: Impute missing values for BIMISC
model_BMISC <- lm(BMISC ~ SEX + SOCIAL + AGEC + POTAST + FIBRPER + ALCPER + SMKSTAT + Identity, data = data, na.action = na.exclude)

data$BMISC[is.na(data$BMISC)] <- predict(model_BMISC, newdata = data[is.na(data$BMISC), ])

# 2: Impute missing values for SYSTOL
model_SYSTOL <- lm(SYSTOL ~ SEX + SOCIAL + AGEC + BMISC + POTAST + FIBRPER + ALCPER + SMKSTAT + Identity, data = data, na.action = na.exclude)

data$SYSTOL[is.na(data$SYSTOL)] <- predict(model_SYSTOL, newdata = data[is.na(data$SYSTOL), ])

# 3: Impute missing values for DIASTOL
model_DIASTOL <- lm(DIASTOL ~ SEX + SOCIAL + AGEC + BMISC + SYSTOL + POTAST  + FIBRPER + ALCPER + SMKSTAT + Identity, data = data, na.action = na.exclude)
data$DIASTOL[is.na(data$DIASTOL)] <- predict(model_DIASTOL, newdata = data[is.na(data$DIASTOL), ])

# Check the imputed values
data1 <- data %>%
  select(-ABSPID,-ABSHID)
vis_miss(data1)
selected_data <- data 
```







## Section 6: Outlier detection

Next we checked the outliers in each numeric variables, we had observed that all the variables except the **AGEC** (which indicate the age of the person) contain ouliers,
```{r,fig.height=10}
numerical_vars <- selected_data %>%
  select_if(is.numeric) 


par(mfrow = c(3, 3)) 
for (var in names(numerical_vars)) {
  boxplot(numerical_vars[[var]], 
          main = var, 
          ylab = var, 
          col = "lightblue",        
          border = "darkblue",      
          outcol = "red",           
          pch = 19                
  )
}
```

As some of those outliers are stil plausible values, we still want to keep them, but we need to consider those inconsistence values which is not in the correct range.


```{r}

normal_ranges <- list( SYSTOL = c(70, 220),  
                       DIASTOL = c(40, 130), 
                       BMISC = c(10, 55),
                       POTAST = c(1000,7500),
                       SODIUMT = c(500,6500),
                       ALCPER = c(0, 30),
                       CHOPER = c(10, 80)
                       ) 
                       
filtered_data <- selected_data %>%
  filter(
    SYSTOL >= normal_ranges$SYSTOL[1] & SYSTOL <= normal_ranges$SYSTOL[2],
    DIASTOL >= normal_ranges$DIASTOL[1] & DIASTOL <= normal_ranges$DIASTOL[2],
    BMISC >= normal_ranges$BMISC[1] & BMISC <= normal_ranges$BMISC[2],
    POTAST >= normal_ranges$POTAST[1] & POTAST <= normal_ranges$POTAST[2],
    SODIUMT >= normal_ranges$SODIUMT[1] & SODIUMT <= normal_ranges$SODIUMT[2],
    ALCPER>= normal_ranges$ALCPER[1] & ALCPER <= normal_ranges$ALCPER[2],
    CHOPER >= normal_ranges$CHOPER[1] & CHOPER <= normal_ranges$CHOPER[2]
  )

filtered_data
```





## Section 7: Calculating extra response & confounding variables 

Subsequently, we add two columns base on the values of two blood pressure measurements. Also calculate the ratio of the sodium and potassium for one of the confounding variable.

```{r}
filtered_data <- filtered_data %>%
  mutate(
    Hypertension = as.factor(case_when(
    SYSTOL >= 120 | DIASTOL >= 80 ~ 1,
    TRUE ~ 0)),
    
    BP_Category = as.factor(case_when(
    SYSTOL < 120 & DIASTOL < 80 ~ 0,      
    SYSTOL >= 120 & SYSTOL <= 129 & DIASTOL < 80 ~ 1,  
    TRUE ~ 2   )),
    
    PS_Ratio = SODIUMT/POTAST
  )%>%
  select(-SODIUMT,-POTAST)

```

# Modelling (without CV for tuning)
## Section 0 Normalisation

```{r}
numeric_cols <- sapply(filtered_data, is.numeric)  

normalized_data <- filtered_data
normalized_data[numeric_cols] <- scale(filtered_data[numeric_cols])
```


## Section 1 Logistic model 

### 1.1 multicollinearity
```{r}
a <- filtered_data %>%
  select(where(is.numeric),-SYSTOL,-DIASTOL)
ggscatmat(a)
```

### 1.2 Logistic regression 
```{r}

r <- glm(Hypertension ~ SOCIAL + SEX + AGEC + BMISC + SMKSTAT + ALCPER + FIBRPER + CHOPER + Identity + PS_Ratio, 
         data = normalized_data, family = binomial())

summary(r)
```



## Section 2 Random Forest




```{r}
# Set a seed for reproducibility
set.seed(123)


rf_model <- randomForest(Hypertension ~ SOCIAL + SEX + AGEC + BMISC + SMKSTAT + ALCPER + FIBRPER + CHOPER + Identity + PS_Ratio,
                         data = normalized_data, 
                         ntree = 500)  

rf_model
```




## Section 3 SVM


```{r}
set.seed(123)
svm_model <- svm(Hypertension ~ SOCIAL + SEX + AGEC + BMISC + SMKSTAT + ALCPER + FIBRPER + CHOPER + Identity + PS_Ratio, 
                 data = normalized_data, 
                 kernel = "radial",  
                 cost = 1,  
                 gamma = 0.1)  


svm_model
```

# Model comparison (5-fold cross validation)

Then we done the cross validation for three models, as for the validity we perform all cross validation for three models base on the same 5 folds 



```{r}
# Set a seed for reproducibility
set.seed(123)

# Create the 5-fold cross-validation indices to ensure the same fold structure for all models
folds <- createFolds(normalized_data$Hypertension, k = 5, returnTrain = TRUE)

# Define train control with fixed indices for cross-validation
train_control <- trainControl(method = "cv", 
                              index = folds,  # Use the same folds for each model
                              savePredictions = "final")



### Logistic Regression ###
logistic_model <- train(Hypertension ~ SOCIAL + SEX + AGEC + BMISC + SMKSTAT + ALCPER + FIBRPER + CHOPER + Identity + PS_Ratio, 
                        data = normalized_data, 
                        method = "glm", 
                        family = binomial(), 
                        trControl = train_control,
                        metric = "Accuracy")


### Random Forest ###
rf_model <- train(Hypertension ~ SOCIAL + SEX + AGEC + BMISC + SMKSTAT + ALCPER + FIBRPER + CHOPER + Identity + PS_Ratio, 
                  data = normalized_data, 
                  method = "rf", 
                  trControl = train_control,
                  tuneLength = 5,  # Number of different mtry values to try (for tuning)
                  metric = "Accuracy",
                  ntree = 500)  # Number of trees

### SVM ###
svm_model <- train(Hypertension ~ SOCIAL + SEX + AGEC + BMISC + SMKSTAT + ALCPER + FIBRPER + CHOPER + Identity + PS_Ratio, 
                   data = normalized_data, 
                   method = "svmRadial", 
                   trControl = train_control,
                   tuneLength = 5,  # Number of gamma and cost values to try
                   metric = "Accuracy")

# Compare the performance of the models
results <- resamples(list(Logistic = logistic_model, RandomForest = rf_model, SVM = svm_model))

# Summary of results (average accuracy, F1 score, etc. for each model)
summary(results)

# Boxplot comparison of accuracy across folds for each model
bwplot(results, metric = "Accuracy")

# Boxplot comparison of F1 score across folds for each model
bwplot(results, metric = "F1")
```












